version: "3.8"
services:
  llama-vulkan:
    image: ghcr.io/zeozeozeo/llama-server-vulkan:latest
    container_name: llama-vulkan
    restart: always
    read_only: true
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    tmpfs:
      - /root/.cache/mesa_shader_cache
    ports:
      - "8001:8080"
    labels:
      io.containers.autoupdate: "registry"
    init: true
